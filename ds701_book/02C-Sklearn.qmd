---
title: 'Essential Tools: Scikit-Learn'
jupyter: python3
code-fold: false
---

## Introduction

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tools4ds/DS701-Course-Notes/blob/main/ds701_book/jupyter_notebooks/02C-Sklearn.ipynb)

In this chapter we discuss another important Python package, Scikit-Learn (sklearn).

::: {.content-visible when-profile="slides"}
## Scikit-Learn
:::
[Scikit-Learn](https://scikit-learn.org/stable/) (sklearn) is a powerful Python package for machine learning. The theoretical underpinnings of the methods introduced in this lecture will be covered in later lectures. The intent of this lecture is to demonstrate

:::: {.incremental}
1. how to implement a machine learning model using Scikit-Learn and
1. understand the structure of the Scikit-Learn API.
::::

:::: {.fragment}
The 2nd point is key, because understanding the generality of the API will allow you to easily work with different sklearn machine learning models.
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn
:::

The general framework for implementing a machine learning models in sklearn is

:::: {.incremental}
1. Import the sklearn objects you need.
1. Prepare the dataset.
1. Instantiate a machine learning object.
1. Train your model on the dataset.
1. Use the trained model to make predictions.
1. Evaluate the performance of the model. 
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn continued
:::

:::: {.fragment}
We will demonstrate the sklearn machine learning framework by working with the sklearn `LinearRegression` object. This object can be used to train a linear model that predicts continuous values. 
::::

:::: {.fragment}
In this example we will work with the california housing dataset. We will see how to predict the median house price based on features, such as the age of the house, average number of bedrooms, etc. 
::::

:::: {.fragment}
We will cover theoretical details of linear regression in the [Linear regression](17-Regression-I-Linear.qmd) lecture.
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn continued
:::

We will also use sklearn when we cover

:::: {.incremental}
- [clustering](06-Clustering-I-kmeans.qmd),
- [SVD](11-Dimensionality-Reduction-SVD-II.qmd),
- [decision trees](14-Classification-I-Decision-Trees.qmd),
- [k nearest neighbors](15-Classification-II-kNN.qmd),
- [Naive Bayes and SVM](16-Classification-III-NB-SVM.qmd),
- [Logistic regression](18-Regression-II-Logistic.qmd).
::::

## Import sklearn

Let's first import all sklearn module and submodules that will be used in the following demonstrations.

```{python}
import sklearn
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

print(sklearn.__version__)
```

## Prepare the dataset

Scikit-Learn provides a variety of datasets in the `datasets` submodule. These can be used to train simple models. Below we import the california housing dataset. We store the data features as a NumPy arrays called $X$ (2-D) and the target (labels) $y$ (1-D). We can see a description of the dataset by using the `.DESCR` attribute.

```{python}
# Fetch data
housing_dataset = fetch_california_housing()
X = housing_dataset["data"]
y = housing_dataset["target"]
print(housing_dataset.DESCR)
```

::: {.content-visible when-profile="slides"}
## Train-test split
:::
We are going to train a model to predict the median house value. To train and test the model we are going to split the dataset into 80% training data and 20% test data. We use the `train_test_split` function from sklearn.

```{python}
# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20 ,random_state=42)
```

::: {.content-visible when-profile="slides"}
## Dataset scaling
:::

:::: {.fragment}
As part of the data preparation we will want to scale the dataset. Datasets often contain data with different orders of magnitude. Scaling the dataset prevents data with a large magnitude from potentially dominating the model. 
::::

:::: {.fragment}
We will use the `StandardScaler` object which scales data to have zero-mean and unit variance (i.e, standard deviation is 1). 

::: {.content-hidden when-profile="slides"}
There are of course other scaling objects. See this [link](https://scikit-learn.org/stable/modules/preprocessing.html) for documentation. 
:::

For this example we are not going to scale the target variables because they represent a price in dollars. Depending on the application, you may need to scale your target variable.
::::

:::: {.fragment}
```{python}
# Scale the data 
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)
```
::::

## Instantiate and train the machine learning object

With our scaled dataset, we are now in a position to instantiate and train our model. The following code accomplishes this.

```{python}
# Create regression model
reg = LinearRegression()
# Train
reg.fit(X_train, y_train)
```

We instantiate a `LinearRegression()` object and store it in a variable called `reg`. We then call the `fit((X_train, y_train)` method to train the model. 

The `fit()` method is a common function to train a variety of models in sklearn. 

## Prediction with the model

The linear regression model has now been trained. To make predictions we use the `predict()` method. This function is also shared across many machine learning model classes.

```{python}
# Predict on test set
y_pred = reg.predict(X_test)
```

The values in `y_pred` are the models predictions of the median house prices based on the input features of `X_test`.

## Evaluating the performance of the model

:::: {.fragment}
To evaluate the performance of the model, we can use the `score()` method, which is also shared across many model objects in sklearn. 
::::

::: {.content-hidden when-profile="slides"}
In addition, we can use specific functions to evaluate the error in our predictions.
:::

:::: {.fragment}
Next is the code that computes the $R^2$ value of the model and the mean squared error.

The $R^2$ value is a number between [0, 1] and provides a measure of how good the fit of the model is. A value of 1 
means the model fits the data perfectly, while a value of 0 indicates there is no linear relationship between the 
observed and predicted values.
::::

:::: {.fragment}
The mean squared error (MSE) is given by the formula

$$ 
\frac{1}{n}\sum_{i}^{n} (y_i - \hat{y}_i)^2,
$$

where $n$ is the number of data points in the target vector, $y_i$ are the true values of the test set (`y_test`), and $\hat{y}_i$ are the predicted values (`y_pred`).
::::

::: {.content-visible when-profile="slides"}
## Computing $R^2$ and MSE
:::

```{python}
# R^2 value
r2 = reg.score(X_test, y_test)
print("The R^2 score is : ", r2)

# Report Mean Square Error (mse)
mse = mean_squared_error(y_test, y_pred)
print("Mean squared error: ", mse)
```