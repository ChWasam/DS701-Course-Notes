---
title: 'Essential Tools: Scikit-Learn'
jupyter: python3
code-fold: false
---

::: {.content-visible when-profile="web"}
## Introduction

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tools4ds/DS701-Course-Notes/blob/main/ds701_book/jupyter_notebooks/02C-Sklearn.ipynb)

In this chapter we discuss another important Python package, Scikit-Learn (sklearn).
:::

::: {.content-visible when-profile="slides"}
## Scikit-Learn
:::
[Scikit-Learn](https://scikit-learn.org/stable/) (sklearn) is a powerful Python package for machine learning. The theoretical underpinnings of the methods introduced in this lecture will be covered in later lectures. The intent of this lecture is to demonstrate

:::: {.incremental}
1. how to implement a machine learning model using Scikit-Learn and
1. understand the structure of the Scikit-Learn API.
::::

:::: {.fragment}
The 2nd point is key, because understanding the generality of the API will allow you to easily work with different sklearn machine learning models.
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn
:::

The general framework for implementing a machine learning models in sklearn is

:::: {.incremental}
1. Import the sklearn objects you need.
1. Prepare the dataset.
1. Instantiate a machine learning object.
1. Train your model on the dataset.
1. Use the trained model to make predictions.
1. Evaluate the performance of the model. 
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn continued
:::

:::: {.fragment}
We will demonstrate the sklearn machine learning framework by working with the sklearn `LinearRegression` object. This object can be used to train a linear model that predicts continuous values. 
::::

:::: {.fragment}
In this example we will work with the california housing dataset. We will see how to predict the median house price based on features, such as the age of the house, average number of bedrooms, etc. 
::::

:::: {.fragment}
We will cover theoretical details of linear regression in the [Linear regression](17-Regression-I-Linear.qmd) lecture.
::::

::: {.content-visible when-profile="slides"}
## Scikit-Learn continued
:::

We will also use sklearn when we cover

:::: {.incremental}
- [clustering](06-Clustering-I-kmeans.qmd),
- [SVD](11-Dimensionality-Reduction-SVD-II.qmd),
- [decision trees](14-Classification-I-Decision-Trees.qmd),
- [k nearest neighbors](15-Classification-II-kNN.qmd),
- [Naive Bayes and SVM](16-Classification-III-NB-SVM.qmd),
- [Logistic regression](18-Regression-II-Logistic.qmd).
::::

## Import sklearn

Let's first import all sklearn module and submodules that will be used in the following demonstrations.

```{python}
import sklearn
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

print(sklearn.__version__)
```

## Fetching Datasets

Scikit-Learn provides a variety of datasets in the [`datasets`](https://scikit-learn.org/stable/api/sklearn.datasets.html) 
that will take care of retrieving.

| Function | Description |
|----------|-------------|  
| [`fetch_20newsgroups`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) | Load the filenames and data from the 20 newsgroups dataset (classification). |
| [`fetch_20newsgroups_vectorized`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html) | Load and vectorize the 20 newsgroups dataset (classification). |
| [`fetch_california_housing`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) | Load the California housing dataset (regression). |
| [`fetch_covtype`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html) | Load the covertype dataset (classification). |
| [`fetch_kddcup99`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html) | Load the kddcup99 network intrusion detection dataset (classification). |
| [`fetch_lfw_pairs`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html) | Load the Labeled Faces in the Wild (LFW) pairs dataset (classification). |
| [`fetch_lfw_people`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html) | Load the Labeled Faces in the Wild (LFW) people dataset (classification). |
| [`fetch_olivetti_faces`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html) | Load the Olivetti faces data-set from AT&T (classification). |
| [`fetch_rcv1`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_rcv1.html) | Load the Reuters Corpus Volume I multilabel dataset of 800K newswire stories (classification). |
| [`fetch_species_distributions`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_species_distributions.html) | Loader for species distribution dataset from Phillips et. |

## Loading Built-in Toy Datasets

| Function | Description |
|----------|-------------|  
| [`load_breast_cancer`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) | Load the breast cancer dataset (classification). |
| [`load_diabetes`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) | Load the diabetes dataset (regression). |
| [`load_digits`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) | Load the digits dataset (classification). |
| [`load_iris`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) | Load the iris dataset (classification). |
| [`load_linnerud`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html) | Load the linnerud physiological and exercise dataset for 20 subjects (regression). |
| [`load_wine`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) | Load the wine dataset (classification). |
| [`load_boston`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) | Load the boston housing dataset (regression). |


## Other Dataset Loading Functions

| Function | Description |
|----------|-------------|  
| [`fetch_file`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_file.html) | Fetch a file from the web if not already present in the local folder, otherwise return file path. Check SHA256 checksum when provided. |
| [`fetch_openml`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html) | Fetch datasets from the over 6K available at [openml](https://www.openml.org/search?type=data&status=active) by name or dataset id. |


::: {.content-visible when-profile="slides"}
## Prepare the dataset
:::

* Below we import the california housing dataset
    * Predict the median house value of a district based on 8 features
* We store the data features as a NumPy arrays called
    * `X` (2-D) and 
    * the target (labels) `y` (1-D). 

```{python}
# Fetch data
housing_dataset = fetch_california_housing()
X = housing_dataset["data"]
y = housing_dataset["target"]
```

---

* We can see a description of the dataset by using the `.DESCR` attribute.

```{python}
print(housing_dataset.DESCR)
```

## Visualization?

Can we visualize the dataset?

::: {.fragment}
Not directly because the dataset has 8 features (8-dimensional).

Later we will talk about dimensionality reduction and clustering techniques that can help us visualize the dataset.
:::

::: {.content-visible when-profile="slides"}
## Train-test split
:::

* We are going to train a model to predict the median house value. 
* To train and test the model we are going to split the dataset into 80% training data and 20% test data. 
* We use the `train_test_split` function from sklearn.

```{python}
# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20 ,random_state=42)
```

::: {.content-visible when-profile="slides"}
## Dataset scaling
:::

:::: {.fragment}
* As part of the data preparation we will want to scale the dataset. 
* Datasets often contain data with different orders of magnitude. 
* Scaling the dataset prevents data with a large magnitude from potentially dominating the model. 
::::

:::: {.fragment}
We will use the `StandardScaler` object which scales data to have zero-mean and unit variance (i.e, standard deviation is 1). 

::: {.content-hidden when-profile="slides"}
There are of course other scaling objects. See this [link](https://scikit-learn.org/stable/modules/preprocessing.html) for documentation. 
:::

For this example we are not going to scale the target variables because they represent a price in dollars. Depending on the application, you may need to scale your target variable.
::::

:::: {.fragment}
```{python}
# Scale the data 
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```
::::

## Instantiate and train the machine learning object

With our scaled dataset, we are now in a position to instantiate and train our model. The following code accomplishes this.

```{python}
# Create regression model
reg = LinearRegression()
# Train
reg.fit(X_train, y_train)
```

We instantiate a `LinearRegression()` object and store it in a variable called `reg`. We then call the `fit((X_train, y_train)` method to train the model. 

The `fit()` method is a common function to train a variety of models in sklearn. 

## Prediction with the model

The linear regression model has now been trained. To make predictions we use the `predict()` method. This function is also shared across many machine learning model classes.

```{python}
# Predict on test set
y_pred = reg.predict(X_test)
```

The values in `y_pred` are the models predictions of the median house prices based on the input features of `X_test`.

## Model Evaluation -- $R^2$

:::: {.fragment}
To evaluate the performance of the model, we can use the `score()` method, which
is also shared across many model objects in sklearn.
::::

:::: {.fragment}
It calculates the $R^2$ value, which is a number between [0, 1] and provides a
measure of how good the fit of the model is. 

A value of 1 means the model fits the data perfectly, while a value of 0
indicates there is no linear relationship between the observed and predicted values.
::::

:::: {.fragment}
$$
R^2 = 1 - \frac{\sum_{i}^{n} (y_i - \hat{y}_i)^2}{\sum_{i}^{n} (y_i - \bar{y})^2}
$$

where $\bar{y}$ is the sample mean of the target vector.
::::

:::: {.fragment}
**Note:** More on this in a later lecture.
::::

## Model Evaluation -- MSE

The mean squared error (MSE) is given by the formula

$$ 
\frac{1}{n}\sum_{i}^{n} (y_i - \hat{y}_i)^2,
$$

where 
    * $n$ is the number of data points in the target vector, 
    * $y_i$ are the true values of the test set (`y_test`), and 
    * $\hat{y}_i$ are the predicted values (`y_pred`).

## Computing $R^2$ and MSE

```{python}
# R^2 value
r2 = reg.score(X_test, y_test)
print("The R^2 score is : ", r2)

# Report Mean Square Error (mse)
mse = mean_squared_error(y_test, y_pred)
print("Mean squared error: ", mse)
```

## Summary

* We demonstrated how to use Scikit-Learn to train a linear regression model.

We saw how to:

* evaluate the performance of the model using the `score()` method and the `mean_squared_error()` function.
* use the `train_test_split()` function to split the dataset into training and test sets.
* use the `StandardScaler()` function to scale the dataset.
* use the `LinearRegression()` function to train the model.
* use the `predict()` function to make predictions.
* use the `score()` function to evaluate the performance of the model.

**You'll get a chance to practice this in the homework.**
