{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Time Series Analysis'\n",
        "jupyter: python3\n",
        "bibliography: references.bib\n",
        "---\n",
        "\n",
        "## Colab\n",
        "\n",
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tools4ds/DS701-Course-Notes/blob/main/ds701_book/jupyter_notebooks/26-TimeSeries.ipynb)\n",
        "\n",
        "\n",
        "# Introduction to Time Series\n",
        "\n",
        "## Definition and Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Load 10 years of AAPL stock prices into a dataframe\n",
        "aapl_data = yf.download('AAPL', start='2022-01-01', end='2024-11-01', progress=False)\n",
        "aapl_close_px = aapl_data['Close']\n",
        "# Plot the closing prices\n",
        "plt = aapl_close_px.plot(label='AAPL', figsize=(10 ,3), ylabel='Price', title='AAPL Stock Price')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- A **time series** is a series of data points or observations recorded at different\n",
        "  or regular time intervals, e.g., hourly, daily, monthly, quarterly, yearly, etc.\n",
        "- **Time Series Analysis** is the process of analyzing time series data to extract\n",
        "  meaningful statistics and other characteristics of the data such as trends,\n",
        "  cycles, and seasonal patterns.\n",
        "- **Time-Series Forecasting** is the process of using statistical models to predict\n",
        "  future values based on past values.\n",
        "\n",
        "## Applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Download a meteorology dataset example\n",
        "# For this example, we will use a sample dataset from NOAA (National Oceanic and Atmospheric Administration)\n",
        "# The dataset contains daily weather observations from the Global Historical Climatology Network (GHCN)\n",
        "\n",
        "if not os.path.exists(os.path.join('data', 'weather_data_filtered_2022.csv')):\n",
        "  # Load the dataset into a dataframe\n",
        "  url = 'https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2022.csv.gz'\n",
        "  column_names = ['ID', 'Date', 'Element', 'Data_Value', 'M_Flag', 'Q_Flag', 'S_Flag', 'Obs_Time']\n",
        "  weather_data = pd.read_csv(url, compression='gzip', header=None, names=column_names)\n",
        "\n",
        "  # Filter the dataset for a specific weather station and element (e.g., daily maximum temperature)\n",
        "  station_id = 'USW00094728'  # Example station ID (New York Central Park)\n",
        "  element = 'TMAX'  # Daily maximum temperature\n",
        "  weather_data_filtered = weather_data[(weather_data['ID'] == station_id) & (weather_data['Element'] == element)]\n",
        "  # Convert the 'Date' column to datetime format\n",
        "  weather_data_filtered.loc[:, 'Date'] = pd.to_datetime(weather_data_filtered['Date'], format='%Y%m%d')\n",
        "  weather_data_filtered.to_csv(os.path.join('data', 'weather_data_filtered_2022.csv'), index=False)\n",
        "  print(\"Filtered weather data has been written to 'data/weather_data_filtered_2022.csv'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the filtered weather data from the CSV file into a dataframe\n",
        "weather_data_filtered = pd.read_csv(os.path.join('data', 'weather_data_filtered_2022.csv'), parse_dates=['Date'])\n",
        "\n",
        "# Plot the daily maximum temperature\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.plot(weather_data_filtered['Date'], weather_data_filtered['Data_Value'] / 10, label='Daily Max Temperature (°C)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Temperature (°C)')\n",
        "plt.title('Daily Maximum Temperature in 2022 - New York Central Park')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Finance**: Time series analysis is used for stock price prediction, risk management, and economic forecasting.\n",
        "- **Economics**: It helps in understanding economic indicators, GDP growth, and inflation rates.\n",
        "- **Meteorology**: Time series data is crucial for weather forecasting, climate change studies, and analyzing seasonal patterns.\n",
        "- **Healthcare**: Time series analysis is used for analyzing patient data, monitoring disease outbreaks, and predicting patient outcomes.\n",
        "- **Marketing**: Time series analysis is used for analyzing sales data, customer behavior, and predicting future trends.\n",
        "- **Manufacturing**: Time series analysis is used for analyzing production data, monitoring equipment performance, and predicting maintenance needs.\n",
        "\n",
        "## Components of a Time Series\n",
        "\n",
        "- **Trend**: Long-term movement in the data. \"Are car model sales going up or down?\"\n",
        "- **Seasonality**: Regular pattern repeating over a known, fixed period. \"Do sales of ice cream increase during the summer?\"\n",
        "- **Acyclic**: Long-term oscillations not of a fixed period. \"Are there long term business cycles in the sales of a product?\"\n",
        "- **Irregular/Noise**: Random variation. \"Are there random variations in the daily temperature that are not explained by the trend or seasonality?\"\n",
        "\n",
        "## Distinction between Time series and Other Types of Data\n",
        "\n",
        "- **Time Series Data**: Data points collected or recorded at specific time intervals. Examples include stock prices, weather data, and sales figures.\n",
        "- **Cross-Sectional Data**: Data collected at a single point in time, representing a snapshot. Examples include survey results and census data.\n",
        "- **Panel Data**: A combination of time series and cross-sectional data, where multiple subjects are observed over time. Examples include longitudinal studies and repeated measures data.\n",
        "\n",
        "## Analysis and Forecasting\n",
        "\n",
        "We'll look at two main aspects of time series analysis:\n",
        "\n",
        "1. Analyzing historical data to answer questions about past behavior\n",
        "2. Forecasting future values based on past values\n",
        "\n",
        "::: {.content-visible when-profile=\"slides\"}\n",
        "## Time and Date Manipulation\n",
        "\n",
        "**Note**:\n",
        "\n",
        "In the course notes version of this chapter, there's a section on time and date\n",
        "manipulation using the `datetime` library and the `pandas` library.\n",
        ":::\n",
        "\n",
        "::: {.content-visible when-profile=\"web\"}\n",
        "# Time and Date Manipulation\n",
        "\n",
        "Many time series data sets are indexed by date or time. The python `datetime`\n",
        "library and the `pandas` library provide a powerful set of tools for manipulating\n",
        "time series data.\n",
        "\n",
        "The [Time Series](https://wesmckinney.com/book/time-series) chapter of the book\n",
        "[Python for Data Analysis, 3rd Ed.](https://wesmckinney.com/book/time-series)\n",
        "provides a good overview of these tools. We'll share a few excerpts here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "print(f\"Date and time when this cell was executed: {now}\")\n",
        "print(f\"Year: {now.year}, month: {now.month}, day: {now.day}\")\n",
        "\n",
        "delta = now - datetime(2024, 1, 1)\n",
        "print(f\"Since beginning of 2024 till when this cell was run there were {delta.days} days and {delta.seconds} seconds.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also convert between strings and datetime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# string to datetime\n",
        "date_string = \"2024-01-01\"\n",
        "date_object = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
        "print(date_object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also format datetime objects as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# datetime to string\n",
        "now_str = now.strftime(\"%Y-%m-%d\")\n",
        "print(now_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See Table 11.2 in the [book](https://wesmckinney.com/book/time-series) for a list of formatting codes.\n",
        "\n",
        "Let's explore some of the pandas time series tools.\n",
        "\n",
        "Create a time series with a datetime index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "longer_ts = pd.Series(np.random.standard_normal(1000),\n",
        "                      index=pd.date_range(\"2022-01-01\", periods=1000))\n",
        "print(type(longer_ts))\n",
        "longer_ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access just the samples from 2023 with simply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "longer_ts[\"2023\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or the month of September 2023:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "longer_ts[\"2023-09\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or slice by date range:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "longer_ts[\"2023-03-01\":\"2023-03-10\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "longer_ts[\"2023-09-15\":]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are many more time series tools available that let you do things like:\n",
        "\n",
        "- Shifting and setting frequencies of date ranges\n",
        "- Time zone handling\n",
        "- Time series resampling\n",
        "- Time series rolling and expanding windows\n",
        "\n",
        "## Moving Window Functions\n",
        "\n",
        "Let's dive into the moving window functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Load 10 years of AAPL stock prices into a dataframe\n",
        "aapl_data = yf.download('AAPL', start='2012-01-01', end='2022-01-01')\n",
        "print(aapl_data.head())\n",
        "\n",
        "aapl_close_px = aapl_data['Close']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot the closing prices\n",
        "plt = aapl_close_px.plot(label='AAPL')\n",
        "aapl_close_px.rolling(window=250).mean().plot(label='250d MA')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "# Visualization\n",
        "\n",
        "Like with any data, it is important to visualize time series data to get a sense of\n",
        "various characteristics.\n",
        "\n",
        "We'll show a few examples of time series plots and include the code to generate them.\n",
        "\n",
        "## Air Passengers Dataset\n",
        "\n",
        "We're going to use a dataset of air passengers per month from 1949 to 1960."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path = os.path.join('data', 'air_passengers_1949_1960.csv')\n",
        "air_passengers = pd.read_csv(path, index_col='Date', parse_dates=True)\n",
        "air_passengers.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time Series Plot\n",
        "\n",
        "Let's look at the time series plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "ts = air_passengers['Number of Passengers']\n",
        "ts.plot(ylabel='Number of Passengers', title='Air Passengers 1949-1960', figsize=(10, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly there are some trends and seasonality in the data.\n",
        "\n",
        "---\n",
        "\n",
        "One way to accentuate that is to use a two-sided plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = air_passengers.index.values\n",
        "y1 = air_passengers['Number of Passengers'].values\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
        "plt.fill_between(x, y1=y1, y2=-y1, color='tab:blue', alpha=0.2)\n",
        "plt.ylim(-800, 800)\n",
        "plt.title('Air Passengers (Two-Sided View)')\n",
        "plt.hlines(y=0, xmin=x[0], xmax=x[-1], color='black', linewidth=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Since there is a clear seasonal pattern in the data, we can plot the data by month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Seasonal plot of air_passengers\n",
        "import seaborn as sns\n",
        "\n",
        "# Extract month and year from the index\n",
        "air_passengers['Month'] = air_passengers.index.month\n",
        "air_passengers['Year'] = air_passengers.index.year\n",
        "\n",
        "# Create a seasonal plot\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.lineplot(data=air_passengers, x='Month', y='Number of Passengers', hue='Year', palette='tab10')\n",
        "plt.title('Seasonal Plot of Air Passengers')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.xlabel('Month')\n",
        "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The seasonality looks like it is increasing over time, but relatively speaking that\n",
        "might not be the case. We can normalize the data by the first month of each year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Normalize the number of passengers by the first month of each year\n",
        "air_passengers['Normalized_Passengers'] = air_passengers.groupby('Year')['Number of Passengers'].transform(lambda x: x / x.iloc[0])\n",
        "\n",
        "# Create a seasonal plot with normalized values\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.lineplot(data=air_passengers, x='Month', y='Normalized_Passengers', hue='Year', palette='tab10')\n",
        "plt.title('Seasonal Plot of Air Passengers (Normalized by First Month of Each Year)')\n",
        "plt.ylabel('Normalized Number of Passengers')\n",
        "plt.xlabel('Month')\n",
        "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the seasonality looks more similar across years, but perhaps it is still\n",
        "increasing a bit over time.\n",
        "\n",
        "---\n",
        "\n",
        "We can also look at the year-wise box plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Year-wise box plot of air passengers\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.boxplot(data=air_passengers, x='Year', y='Number of Passengers', palette='tab10')\n",
        "plt.title('Year-wise Box Plot of Air Passengers')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.xlabel('Year')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see the trends, median, and interquartile range of the data by year.\n",
        "\n",
        "---\n",
        "\n",
        "We can also look at the seasonal subseries box plot that indicates the\n",
        "distribution of the data over the years for each month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Draw seasonal subseries plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a subseries plot for each month\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.boxplot(data=air_passengers, x='Month', y='Number of Passengers', palette='tab10', hue='Month', legend=False)\n",
        "plt.title('Seasonal Subseries Plot of Air Passengers')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.xlabel('Month')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We can also look at the seasonal subseries plot that shows the trend over the years\n",
        "for each month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Create seasonal subseries plot of monthly passengers\n",
        "fig, axes = plt.subplots(1, 12, figsize=(10, 4), sharey=True)\n",
        "fig.suptitle('Seasonal Subseries Plot of Monthly Air Passengers')\n",
        "\n",
        "# List of abbreviated month names\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "# Iterate over each month and create a subplot\n",
        "for i, ax in enumerate(axes.flatten(), start=1):\n",
        "    monthly_data = air_passengers[air_passengers['Month'] == i]\n",
        "    ax.plot(monthly_data['Year'], monthly_data['Number of Passengers'], marker='.')\n",
        "    ax.set_title(month_names[i-1])\n",
        "    ax.set_xticks([])  # Remove x-axis numbers\n",
        "    # ax.set_xlabel('Year')\n",
        "    #ax.set_ylabel('Number of Passengers')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autocorrelation Function\n",
        "\n",
        "For the next visualization, we will use the autocorrelation function (ACF).\n",
        "\n",
        "* The autocorrelation function (ACF) measures the correlation between a time series and its lagged values. \n",
        "* It helps to identify the extent to which current values of the series are related to its past values. \n",
        "* The ACF is useful for identifying patterns such as seasonality and for determining the appropriate parameters for time series models like ARIMA.\n",
        "\n",
        "## ACF Definition\n",
        "\n",
        "The autocorrelation function at lag $k$ is defined as:\n",
        "\n",
        "$$\n",
        "\\rho_k = \\frac{\\sum_{t=k+1}^{T} (y_t - \\bar{y})(y_{t-k} - \\bar{y})}{\\sum_{t=1}^{T} (y_t - \\bar{y})^2},\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $y_t$ is the value of the time series at time $t$,\n",
        "- $\\bar{y}$ is the mean of the time series,\n",
        "- $T$ is the total number of observations,\n",
        "- $k$ is the lag.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- **Peaks in Autocorrelation**: Indicate that there are cyclic components.\n",
        "- **No Autocorrelation**: Indicates that the values of the series are independent of each other.\n",
        "\n",
        "## ACF Example in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function with noise added\n",
        "def interesting_function(t):\n",
        "    return np.sin(t) + 0.5 * np.random.normal(size=len(t))\n",
        "\n",
        "# Generate time values\n",
        "t = np.linspace(0, 10, 500)\n",
        "\n",
        "# Generate the function values\n",
        "function_values = interesting_function(t)\n",
        "\n",
        "# Shift the function values\n",
        "shift = 50\n",
        "function_values_shifted = np.roll(function_values, shift)\n",
        "\n",
        "# Plot the function and its shifted version\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(t, function_values, label='Original Function')\n",
        "plt.plot(t, function_values_shifted, label='Shifted Function', linestyle='dashed')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Original Function and Shifted Function with Noise')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Compute the autocorrelation\n",
        "autocorrelation = np.correlate(function_values, function_values_shifted, mode='full')\n",
        "lags = np.arange(-len(function_values) + 1, len(function_values))\n",
        "\n",
        "# Plot the autocorrelation\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(lags, autocorrelation)\n",
        "plt.xlabel('Lag')\n",
        "plt.ylabel('Autocorrelation')\n",
        "plt.title('Autocorrelation of Function with Noise')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ACF of Air Passengers\n",
        "\n",
        "An interesting perspective is to plot the autocorrelation to see if there are any\n",
        "significant lags in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "# Draw the autocorrelation plot of air passengers\n",
        "plot_acf(air_passengers['Number of Passengers'], lags=48)\n",
        "plt.title('Autocorrelation Plot of Air Passengers')\n",
        "plt.xlabel('Lags')\n",
        "plt.ylabel('Autocorrelation')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The blue shaded area is the 95% confidence interval. The autocorrelation is\n",
        "significant when it is outside the confidence interval, e.g., the peak at 12. \n",
        "\n",
        "Although we can see peaks at lags 24, 36, and 48, they are not statistically significant.\n",
        "\n",
        "\n",
        "# Components of Time Series\n",
        "\n",
        "Let's now try to decompose the time series into constituent components.\n",
        "\n",
        "First we'll define the components and then look at how we find them.\n",
        "\n",
        "## Trend\n",
        "\n",
        "- **Trend**: Represents the long-term progression of the series. It can be increasing, decreasing, or constant over time.\n",
        "- **Examples**: \n",
        "  - An upward trend in stock prices over several years.\n",
        "  - A downward trend in the sales of a product as it becomes obsolete.\n",
        "\n",
        "## Seasonality\n",
        "\n",
        "- **Seasonality**: Refers to regular, predictable changes that recur every calendar year. It is a pattern that repeats over a known, fixed period.\n",
        "- **Examples**: \n",
        "  - Increased retail sales during the holiday season.\n",
        "  - Higher ice cream sales during the summer months.\n",
        "  - Regular fluctuations in electricity consumption due to seasonal temperature changes.\n",
        "\n",
        "## Cyclic (Acyclic)\n",
        "\n",
        "- **Cyclic**: Refers to long-term oscillations or fluctuations in the data that are not of a fixed period. These cycles can vary in length and are often influenced by economic or business conditions.\n",
        "- **Examples**: \n",
        "  - Business cycles with periods of expansion and contraction.\n",
        "  - Agricultural cycles influenced by factors such as weather and market conditions.\n",
        "\n",
        "## Irregular/Noise\n",
        "\n",
        "- **Irregular/Noise**: Refers to the random variation in the data that cannot be attributed to trend, seasonality, or cyclic patterns. It is the residual variation after accounting for other components.\n",
        "- **Examples**: \n",
        "  - Sudden spikes or drops in stock prices due to unexpected news.\n",
        "  - Random fluctuations in daily temperature readings.\n",
        "  - Unpredictable changes in sales figures due to unforeseen events.\n",
        "\n",
        "# Time Series Decomposition\n",
        "\n",
        "Let's look at _how_ we can decompose the time series into its components.\n",
        "\n",
        "## Combination of components\n",
        "\n",
        "We've identified the components of the time series. Now we need to combine them.\n",
        "\n",
        "There are two main ways to combine the components:\n",
        "\n",
        "- **Additive model**\n",
        "- **Multiplicative model**\n",
        "\n",
        "## Additive model\n",
        "\n",
        "- **Additive Model**: Assumes that the components of the time series (trend, seasonality, and noise) are added together. The model can be represented as\n",
        "  - $Y(t) = T(t) + S(t) + e(t)$\n",
        "  - Where $Y(t)$ is the observed value, $T(t)$ is the trend component, $S(t)$ is the seasonal component, and $e(t)$ is the noise or error term.\n",
        "- **Example**:\n",
        "  - Monthly sales data where the seasonal effect is constant over time.\n",
        "\n",
        "## Multiplicative model\n",
        "\n",
        "- **Multiplicative Model**: Assumes that the components of the time series are multiplied together. The model can be represented as:\n",
        "  - $Y(t) = T(t) \\times S(t) \\times e(t)$\n",
        "  - Where $Y(t)$, $T(t)$ and $S(t)$ are the trend, seasonal, and noise components respectively.\n",
        "- **Examples**\n",
        "  - Monthly sales data where the seasonal effect increases or decreases proportionally with the trend.\n",
        "\n",
        "## Decomposition Approaches\n",
        "\n",
        "We'll look at two approaches to decomposing the time series:\n",
        "\n",
        "- **Classical Decomposition**\n",
        "- **STL Decomposition**\n",
        "\n",
        "Both approaches support additive and multiplicative models.\n",
        "\n",
        "## Classical Decomposition\n",
        "\n",
        "- This technique involves breaking down a time series into its **trend**,\n",
        "  **seasonal**, and **irregular** (or noise) components. \n",
        "- It can be applied using either an additive or multiplicative model.\n",
        "- **Steps**:\n",
        "  1. Estimate the trend component by applying a moving average.\n",
        "  2. Remove the trend component to get the detrended series.\n",
        "  3. Estimate the seasonal component from the detrended series.\n",
        "  4. Remove the seasonal component to get the irregular component.\n",
        "\n",
        "Let's take each step by step.\n",
        "\n",
        "## Estimating the Trend\n",
        "\n",
        "First we'll estimate the trend component by applying a moving average using the\n",
        "Pandas `rolling` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "ts.plot(figsize=(8, 3), label='Monthly')\n",
        "ts.rolling(window=11, center=True).mean().plot(label='11m MA')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.title('Air Passengers 1949-1960')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're actually using a 11-month moving average because we want to center the\n",
        "average.\n",
        "\n",
        "## Removing the Trend\n",
        "\n",
        "Now we can subtract the trend component to get the detrended series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "detrended_ts = ts - ts.rolling(window=11, center=True).mean()\n",
        "detrended_ts.plot(figsize=(8, 3), label='Detrended')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.title('Air Passengers 1949-1960')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimating Seasonality\n",
        "\n",
        "Estimate the seasonal component by taking the mean of the detrended\n",
        "series for each month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "seasonal_ts = detrended_ts.groupby(detrended_ts.index.month).mean()\n",
        "seasonal_ts.plot(figsize=(8, 3), label='Seasonal')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.title('Air Passengers 1949-1960')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We can also look at the box plot of the detrended series for each month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Box plot of the detrended series for each month\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a DataFrame with the detrended series and the corresponding month\n",
        "detrended_df = pd.DataFrame({'Detrended': detrended_ts, 'Month': detrended_ts.index.month})\n",
        "\n",
        "# Plot the box plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x='Month', y='Detrended', data=detrended_df, palette='tab10', hue='Month', legend=False)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Detrended Number of Passengers')\n",
        "plt.title('Box Plot of Detrended Air Passengers by Month')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly, certain months have more variability than others.\n",
        "\n",
        "## Removing Seasonality\n",
        "\n",
        "Now we can subtract the seasonal component to get the irregular component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "# Broadcast the seasonal component to the length of the detrended series\n",
        "# and subtract it from the detrended series\n",
        "\n",
        "irregular_ts = detrended_ts - np.tile(seasonal_ts, len(detrended_ts) // len(seasonal_ts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And plot the residual irregular component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "plt.figure(figsize=(8, 3))\n",
        "irregular_ts.plot(label='Irregular', color='red')\n",
        "plt.ylabel('Irregular')\n",
        "plt.title('Irregular Component')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question**: What do you observe about the irregular component? Is it truly\n",
        "random?\n",
        "\n",
        "---\n",
        "\n",
        "Finally, we can put the detrended, seasonal, and irregular plots together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Plot detrended, seasonal, and irregular components\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot detrended series\n",
        "plt.subplot(3, 1, 1)\n",
        "detrended_ts.plot(label='Detrended', color='blue')\n",
        "plt.ylabel('Detrended')\n",
        "plt.title('Detrended Component')\n",
        "plt.legend()\n",
        "\n",
        "# Plot seasonal series\n",
        "plt.subplot(3, 1, 2)\n",
        "seasonal_ts.plot(label='Seasonal', color='green')\n",
        "plt.ylabel('Seasonal')\n",
        "plt.title('Seasonal Component')\n",
        "plt.legend()\n",
        "\n",
        "# Plot irregular series\n",
        "plt.subplot(3, 1, 3)\n",
        "irregular_ts.plot(label='Irregular', color='red')\n",
        "plt.ylabel('Irregular')\n",
        "plt.title('Irregular Component')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seasonality and Trend Decomposition (STL)\n",
        "\n",
        "- **STL** is a more flexible and robust method for decomposing time series data.\n",
        "- It uses locally weighted regression (Loess) to estimate the trend and seasonal components [@cleveland1990stl].\n",
        "- **Advantages**:\n",
        "  - Handles any type of seasonality (e.g., weekly, monthly).\n",
        "  - Can deal with missing values and outliers.\n",
        "  - Provides smooth and adaptable trend and seasonal components.\n",
        "\n",
        "> See [Course Notes](#locally-estimated-scatterplot-smoothing----loessgpt4o) for a more detailed description of Loess.\n",
        "\n",
        "See also [@hyndman2021forecasting].\n",
        "\n",
        "::: {.content-visible when-profile=\"web\"}\n",
        "\n",
        "## Locally Estimated Scatterplot Smoothing -- Loess[^gpt4o]\n",
        "\n",
        "[^gpt4o]: gpt-4o, personal communication, Nov 2024\n",
        "\n",
        "**Loess**, which stands for \"Locally Estimated Scatterplot Smoothing,\" is a non-parametric method used to estimate non-linear relationships in data. It is particularly useful for smoothing scatterplots and is a type of local regression.\n",
        "\n",
        "### Key Features of Loess:\n",
        "\n",
        "1. **Local Fitting**: Loess fits simple models to localized subsets of the data to build up a function that describes the deterministic part of the variation in the data, point by point.\n",
        "\n",
        "2. **Weighted Least Squares**: It uses weighted least squares to fit a polynomial surface to the data. The weights decrease with distance from the point of interest, giving more influence to points near the target point.\n",
        "\n",
        "3. **Flexibility**: Loess is flexible and can model complex relationships without assuming a specific global form for the data. It can adapt to various shapes and patterns in the data.\n",
        "\n",
        "4. **Smoothing Parameter**: The degree of smoothing is controlled by a parameter, often denoted as $\\alpha$ or the span. This parameter determines the proportion of data points used in each local fit. A smaller span results in a curve that follows the data more closely, while a larger span results in a smoother curve.\n",
        "\n",
        "5. **Polynomial Degree**: Loess can fit either linear or quadratic polynomials to the data. The choice of polynomial degree affects the smoothness and flexibility of the fit.\n",
        "\n",
        "### How Loess Works:\n",
        "\n",
        "- **Step 1**: For each point in the dataset, a neighborhood of points is selected based on the smoothing parameter.\n",
        "- **Step 2**: A weighted least squares regression is performed on the points in the neighborhood, with weights decreasing with distance from the target point.\n",
        "- **Step 3**: The fitted value at the target point is computed from the local regression model.\n",
        "- **Step 4**: This process is repeated for each point in the dataset, resulting in a smooth curve that captures the underlying trend.\n",
        "\n",
        "### Applications:\n",
        "\n",
        "Loess is widely used in exploratory data analysis to visualize trends and patterns in data. It is particularly useful when the relationship between variables is complex and not well-represented by a simple linear or polynomial model.\n",
        "\n",
        "### Example in Python:\n",
        "\n",
        "In Python, the `statsmodels` library provides a function for performing Loess smoothing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Example data\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x) + np.random.normal(0, 0.1, 100)\n",
        "\n",
        "# Apply Loess smoothing\n",
        "smoothed = lowess(y, x, frac=0.2)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(x, y, label='Data', alpha=0.5)\n",
        "plt.plot(smoothed[:, 0], smoothed[:, 1], color='red', label='Loess Smoothed')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, `frac` is the smoothing parameter that controls the amount of smoothing applied to the data.\n",
        ":::\n",
        "\n",
        "## Practical example using Python\n",
        "\n",
        "Let's demonstrate a practical example of time series decomposition using Python.\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "1. Load a sample time series dataset.\n",
        "2. Apply a decomposition technique (e.g., classical decomposition or STL).\n",
        "3. Visualize the decomposed components (trend, seasonal, and residual).\n",
        "\n",
        "\n",
        "## Air Passengers Dataset\n",
        "\n",
        "Let's load the Air Passengers dataset again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Load a sample time series dataset\n",
        "data = pd.read_csv(os.path.join('data', 'air_passengers_1949_1960.csv'), index_col='Date', parse_dates=True)\n",
        "ts = data['Number of Passengers']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `statsmodels` Additive Model\n",
        "\n",
        "We'll apply the classical decomposition using the `statsmodels` \n",
        "`seasonal_decompose` function with the additive model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Apply classical decomposition\n",
        "decomposition = seasonal_decompose(ts, model='additive')\n",
        "\n",
        "# Plot the decomposed components\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(8, 8))\n",
        "decomposition.observed.plot(ax=ax1)\n",
        "ax1.set_ylabel('Observed')\n",
        "ax1.set_title('Air Passengers 1949-1960')\n",
        "decomposition.trend.plot(ax=ax2)\n",
        "ax2.set_ylabel('Trend')\n",
        "decomposition.seasonal.plot(ax=ax3)\n",
        "ax3.set_ylabel('Seasonal')\n",
        "decomposition.resid.plot(ax=ax4)\n",
        "ax4.set_ylabel('Residual')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `statsmodels` Multiplicative Model\n",
        "\n",
        "Let's try the multiplicative model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "# Apply classical decomposition\n",
        "decomposition = seasonal_decompose(ts, model='multiplicative')\n",
        "\n",
        "# Plot the decomposed components\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(8, 8))\n",
        "decomposition.observed.plot(ax=ax1)\n",
        "ax1.set_ylabel('Observed')\n",
        "decomposition.trend.plot(ax=ax2)\n",
        "ax2.set_ylabel('Trend')\n",
        "decomposition.seasonal.plot(ax=ax3)\n",
        "ax3.set_ylabel('Seasonal')\n",
        "decomposition.resid.plot(ax=ax4)\n",
        "ax4.set_ylabel('Residual')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STL Decomposition\n",
        "\n",
        "The STL decomposition is more flexible and can handle the seasonality in the data\n",
        "better.\n",
        "\n",
        "Let's try the STL decomposition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center \n",
        "from statsmodels.tsa.seasonal import STL\n",
        "\n",
        "stl = STL(ts, period=12, robust=True)\n",
        "result = stl.fit()\n",
        "# result.plot()\n",
        "\n",
        "# Plot the decomposed components\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(8, 6))\n",
        "result.observed.plot(ax=ax1)\n",
        "ax1.set_ylabel('Observed')\n",
        "ax1.set_title('Air Passengers 1949-1960 (STL)')\n",
        "result.trend.plot(ax=ax2)\n",
        "ax2.set_ylabel('Trend')\n",
        "result.seasonal.plot(ax=ax3)\n",
        "ax3.set_ylabel('Seasonal')\n",
        "result.resid.plot(ax=ax4)\n",
        "ax4.set_ylabel('Residual')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stationarity and Differencing\n",
        "\n",
        "## Definition of Stationarity\n",
        "\n",
        "A time series is said to be stationary if its statistical properties such as mean, variance, and autocorrelation are constant over time.\n",
        "\n",
        "**Types of Stationarity**:\n",
        "\n",
        "1. **Strict Stationarity**: The entire distribution of the time series remains unchanged over time.\n",
        "2. **Weak Stationarity**: Only the first two moments (mean and variance) are constant over time, and the covariance between two time points depends only on the time lag between them.\n",
        "\n",
        "## Importance of Stationarity\n",
        "\n",
        "Stationarity is crucial in time series analysis because many statistical methods and models assume that the time series is stationary. Non-stationary data can lead to misleading results and poor forecasts.\n",
        "\n",
        "**Why Stationarity Matters**\n",
        "\n",
        "1. **Model Assumptions**: Many time series models, such as ARIMA, require the data to be stationary to make accurate predictions.\n",
        "2. **Statistical Properties**: Stationary time series have consistent statistical properties over time, making it easier to analyze and interpret.\n",
        "3. **Forecasting**: Stationary data improves the reliability and accuracy of forecasts.\n",
        "\n",
        "## Techniques to Achieve Stationarity\n",
        "\n",
        "1. **Differencing**: Subtracting the previous observation from the current observation to remove trends and seasonality.\n",
        "2. **Transformation**: Applying mathematical transformations such as logarithms or square roots to stabilize the variance.\n",
        "3. **Decomposition**: Separating the time series into trend, seasonal, and residual components to analyze and adjust each part individually.\n",
        "4. **Smoothing**: Using techniques like moving averages to smooth out short-term fluctuations and highlight longer-term trends.\n",
        "\n",
        "## Tests for Stationarity\n",
        "\n",
        "There are tests for stationarity such as listed below and available in\n",
        "`statsmodels`.\n",
        "\n",
        "- **ADF Test (Augmented Dickey-Fuller Test)**: A statistical test used to determine\n",
        "  if a time series is stationary. It tests the null hypothesis that a unit root[^unit_root] is\n",
        "  present in the time series.\n",
        "- **KPSS Test (Kwiatkowski-Phillips-Schmidt-Shin Test)**: Another test for\n",
        "  stationarity that tests the null hypothesis that the time series is stationary\n",
        "  around a deterministic trend.\n",
        "\n",
        "[^unit_root]: Unit root relates to stability in autoregressive models. AR models can be expressed as polynomial equations and the value of the roots of the polynomial determine the stability of the model after perturbation. Roots on the unit circle will indicate that perturbations will have a permanent effect, making the model non-stationary.\n",
        "\n",
        "::: {.content-visible when-profile=\"web\"}\n",
        "\n",
        "## ADF Test Demonstration\n",
        "\n",
        "Let's apply the tests, starting with ADF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "air_passengers = pd.read_csv(os.path.join('data', 'air_passengers_1949_1960.csv'))\n",
        "\n",
        "# Apply ADF and KPSS tests on the air passenger data\n",
        "\n",
        "# ADF Test\n",
        "result_adf = adfuller(air_passengers['Number of Passengers'])\n",
        "print('ADF Statistic:', result_adf[0])\n",
        "print('p-value:', result_adf[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result_adf[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation:\n",
        "\n",
        "1. **ADF Statistic**: The ADF statistic is 0.815, which is greater than all the critical values at the 1%, 5%, and 10% significance levels.\n",
        "\n",
        "2. **p-value**: The p-value is 0.991, which is significantly higher than common significance levels (e.g., 0.01, 0.05, 0.10).\n",
        "\n",
        "3. **Critical Values**:\n",
        "   - 1%: -3.482\n",
        "   - 5%: -2.884\n",
        "   - 10%: -2.579\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "- **Fail to Reject the Null Hypothesis**: Since the ADF statistic (0.815) is greater than the critical values and the p-value (0.991) is much higher than typical significance levels, you fail to reject the null hypothesis. This suggests that the time series has a unit root and is non-stationary.\n",
        "\n",
        "- **Implication**: The time series data for the number of passengers is non-stationary, indicating that it may have a trend or other non-stationary components. To make the series stationary, you might consider differencing the data or applying other transformations, such as detrending or seasonal adjustment, before proceeding with further analysis or modeling.\n",
        "\n",
        "## KPSS Test Demonstration\n",
        "\n",
        "Let's apply the KPSS test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# KPSS Test\n",
        "result_kpss = kpss(air_passengers['Number of Passengers'], regression='c')\n",
        "print('\\nKPSS Statistic:', result_kpss[0])\n",
        "print('p-value:', result_kpss[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result_kpss[3].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The KPSS (Kwiatkowski-Phillips-Schmidt-Shin) test is another test used to assess the stationarity of a time series, but it has a different null hypothesis compared to the ADF test.\n",
        "\n",
        "### KPSS Test Interpretation:\n",
        "\n",
        "1. **Null Hypothesis (\\(H_0\\))**: The null hypothesis of the KPSS test is that the time series is stationary around a deterministic trend (i.e., it does not have a unit root).\n",
        "\n",
        "2. **Alternative Hypothesis (\\(H_1\\))**: The alternative hypothesis is that the time series is not stationary (i.e., it has a unit root).\n",
        "\n",
        "### Given Results:\n",
        "\n",
        "- **KPSS Statistic**: 1.651\n",
        "- **p-value**: 0.01\n",
        "- **Critical Values**:\n",
        "  - 10%: 0.347\n",
        "  - 5%: 0.463\n",
        "  - 2.5%: 0.574\n",
        "  - 1%: 0.739\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "- **Reject the Null Hypothesis**: The KPSS statistic (1.651) is greater than all the critical values at the 10%, 5%, 2.5%, and 1% significance levels. This, along with the low p-value (0.01), suggests that you reject the null hypothesis of stationarity.\n",
        "\n",
        "- **Implication**: The time series is likely non-stationary according to the KPSS test. This aligns with the ADF test results, which also indicated non-stationarity.\n",
        "\n",
        "### Overall Interpretation:\n",
        "\n",
        "Both the ADF and KPSS tests suggest that the time series is non-stationary. This consistent result from both tests strengthens the conclusion that the series may need differencing or other transformations to achieve stationarity before further analysis or modeling.\n",
        "\n",
        ":::\n",
        "\n",
        "# Time Series Models\n",
        "\n",
        "In order to forecast future data values, we will now define a family of models\n",
        "and then apply one to our data.\n",
        "\n",
        "## Autoregressive (AR) models\n",
        "\n",
        "A type of time series model where the current value of the series is based on\n",
        "its previous values. \n",
        "  \n",
        "The model is defined as\n",
        "\n",
        "$$\n",
        "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\epsilon_t,\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $y_t$ is the current value,\n",
        "- $c$ is a constant,\n",
        "- $\\phi_1, \\phi_2, \\ldots, \\phi_p$ are the coefficients,\n",
        "- $\\epsilon_t$ is the white noise error term.\n",
        "\n",
        "--- \n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "1. **Lag Order (p)**: The number of lagged observations included in the model.\n",
        "2. **Stationarity**: The series should be stationary for the AR model to be effective.\n",
        "3. **Parameter Estimation**: Methods like Yule-Walker equations or Maximum Likelihood Estimation (MLE) are used to estimate the parameters, $\\phi_i$.\n",
        "\n",
        "## Moving Average (MA) models\n",
        "\n",
        "A type of time series model where the current value of the series is based on\n",
        "past forecast errors. The model is defined as\n",
        "\n",
        "$$\n",
        "y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\ldots + \\theta_q \\epsilon_{t-q},\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $y_t$ is the current value,\n",
        "- $\\mu$ is the mean of the series,\n",
        "- $\\epsilon_t$ is the white noise error term,\n",
        "- $\\theta_1, \\theta_2, \\ldots, \\theta_q$ are the coefficients.\n",
        "\n",
        "---\n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "  1. **Lag Order (q)**: The number of lagged forecast errors included in the model.\n",
        "  2. **Stationarity**: The series should be stationary for the MA model to be effective.\n",
        "  3. **Parameter Estimation**: Methods like Maximum Likelihood Estimation (MLE) are used to estimate the parameters $\\theta_i$.\n",
        "\n",
        "## Autoregressive Integrated Moving Average (ARIMA) Models\n",
        "\n",
        "A type of time series model that combines Autoregressive (AR) and Moving Average\n",
        "(MA) models with differencing to make the series stationary.\n",
        "\n",
        "The model is defined as\n",
        "\n",
        "$$\n",
        "y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\ldots + \\theta_q \\epsilon_{t-q},\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $y_t$ is the current value,\n",
        "- $c$ is a constant,\n",
        "- $\\phi_1, \\phi_2, \\ldots, \\phi_p$ are the AR coefficients,\n",
        "- $\\epsilon_t$ is the white noise error term,\n",
        "- $\\theta_1, \\theta_2, \\ldots, \\theta_q$ are the MA coefficients.\n",
        "\n",
        "---\n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "1. **Order (p, d, q)**: The parameters of the ARIMA model where $p$ is the number of lag observations, $d$ is the degree of differencing, and $q$ is the size of the moving average window.\n",
        "2. **Stationarity**: Differencing is used to make the series stationary.\n",
        "3. **Parameter Estimation**: Methods like Maximum Likelihood Estimation (MLE) are used to estimate the parameters.\n",
        "\n",
        "\n",
        "## Seasonal ARIMA (SARIMA) Models\n",
        "\n",
        "A type of time series model that extends ARIMA to support seasonality. The model\n",
        "is defined as\n",
        "\n",
        "$$\n",
        "\\begin{aligned} \n",
        "y_t &= c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\epsilon_t \\\\ \n",
        "&\\quad + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\ldots + \\theta_q \\epsilon_{t-q} \\\\ \n",
        "&\\quad + \\Phi_1 Y_{t-s} + \\Phi_2 Y_{t-2s} + \\ldots + \\Phi_P Y_{t-Ps} \\\\ \n",
        "&\\quad + \\Theta_1 E_{t-s} + \\Theta_2 E_{t-2s} + \\ldots + \\Theta_Q E_{t-Qs} \n",
        "\\end{aligned} \n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $y_t$ is the current value,\n",
        "- $c$ is a constant,\n",
        "- $\\phi_1, \\phi_2, \\ldots, \\phi_p$ are the AR coefficients,\n",
        "- $\\epsilon_t$ is the white noise error term,\n",
        "- $\\theta_1, \\theta_2, \\ldots, \\theta_q$ are the MA coefficients,\n",
        "- $\\Phi_1, \\Phi_2, \\ldots, \\Phi_P$ are the seasonal AR coefficients,\n",
        "- $Y_{t-s}, Y_{t-2s}, \\ldots, Y_{t-Ps}$ are the seasonal lagged observations,\n",
        "- $\\Theta_1, \\Theta_2, \\ldots, \\Theta_Q$ are the seasonal MA coefficients,\n",
        "- $E_{t-s}, E_{t-2s}, \\ldots, E_{t-Qs}$ are the seasonal lagged forecast errors.\n",
        "\n",
        "---\n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "1. **Order (p, d, q) x (P, D, Q, s)**: The parameters of the SARIMA model where $p, d, q$ are the non-seasonal parameters, $P, D, Q$ are the seasonal parameters, and $s$ is the length of the seasonal cycle.\n",
        "2. **Stationarity**: Differencing is used to make the series stationary.\n",
        "3. **Parameter Estimation**: Methods like Maximum Likelihood Estimation (MLE) are used to estimate the parameters.\n",
        "\n",
        "\n",
        "## ARIMA/SARIMA Example\n",
        "\n",
        "Let's look at a concrete example of ARIMA/SARIMA using the Air Passengers dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll load the dataset and show the head."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path = os.path.join('data', 'air_passengers_1949_1960.csv')\n",
        "data = pd.read_csv(path)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Next, use pandas `date_range` method to create a new month column. We could have\n",
        "used date string conversion tools on the `Date` column alternatively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data['Month'] = pd.date_range(start='1949-01', periods=len(data), freq='ME')\n",
        "data.set_index('Month', inplace=True)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "As a next step, we'll log transform the data to stabilize the variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Log transform to stabilize variance\n",
        "data['Log_Passengers'] = np.log(data['Number of Passengers'])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "And finally, we'll perform a **classical additive seasonal decomposition** of the data as a point\n",
        "of comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Seasonal decomposition\n",
        "decomposition = seasonal_decompose(data['Log_Passengers'], model='additive')\n",
        "decomposition.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SARIMAX Model\n",
        "\n",
        "Now let's create an instance of a **SARIMAX** model -- <b>S</b>easonal \n",
        "<b>A</b>utoregressive <b>I</b>ntegrated <b>M</b>oving <b>A</b>verage with \n",
        "e<b>X</b>ogenous regressors.\n",
        "\n",
        "It extends the SARIMA model to support exogenous variables, although we aren't using any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "# SARIMA model\n",
        "model = SARIMAX(data['Log_Passengers'], \n",
        "                order=(1, 1, 1), \n",
        "                seasonal_order=(1, 1, 1, 12), \n",
        "                freq='ME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The configuration is as follows:\n",
        "\n",
        "- We'll use the `Log_Passengers` as the time series, which has better variance properties.\n",
        "- `order=(1, 1, 1)` means we're using an ARIMA model with 1 autoregressive term, 1 differencing term, and 1 moving average term.\n",
        "- `seasonal_order=(1, 1, 1, 12)` means we're using a seasonal ARIMA model with 1 autoregressive term, 1 differencing term, 1 moving average term, and a seasonal cycle of 12 months.\n",
        "- The frequency is the month-end, or `ME`.\n",
        "\n",
        "---\n",
        "\n",
        "We'll fit the model which also prints the fit summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We'll print the summary and plot the diagnostics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary and diagnostics\n",
        "print(results.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "And let's plot some diagnostic information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results.plot_diagnostics(figsize=(12, 8))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation of SARIMAX Diagnostics\n",
        "\n",
        "The `plot_diagnostics` function provides several diagnostic plots to evaluate the fit of the SARIMAX model. Here is an explanation of each panel:\n",
        "\n",
        "1. **Standardized Residuals**:\n",
        "   - This plot shows the residuals (differences between the observed and predicted values) standardized to have zero mean and unit variance.\n",
        "   - Ideally, the residuals should appear as white noise, meaning they should be randomly scattered around zero with no discernible pattern.\n",
        "\n",
        "2. **Histogram plus KDE**:\n",
        "   - This panel displays a histogram of the residuals along with a Kernel Density Estimate (KDE) to visualize the distribution.\n",
        "   - The histogram should resemble a normal distribution if the model is well-fitted. The KDE line helps to see the shape of the distribution more clearly.\n",
        "\n",
        "3. **Normal Q-Q Plot**:\n",
        "   - The Q-Q plot compares the quantiles of the residuals to the quantiles of a standard normal distribution.\n",
        "   - If the residuals are normally distributed, the points should lie approximately along the 45-degree line.\n",
        "\n",
        "4. **Correlogram (ACF Plot)**:\n",
        "   - This plot shows the autocorrelation function (ACF) of the residuals.\n",
        "   - The ACF plot helps to identify any remaining autocorrelation in the residuals. Ideally, the residuals should have no significant autocorrelation, indicating that the model has captured all the temporal dependencies.\n",
        "\n",
        "---\n",
        "\n",
        "Finally, let's make a forecast for 2 years out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Forecasting\n",
        "forecast = results.get_forecast(steps=24)\n",
        "forecast_index = pd.date_range(data.index[-1] + pd.DateOffset(months=1), periods=24, freq='ME')\n",
        "forecast_values = np.exp(forecast.predicted_mean)  # Convert back from log\n",
        "confidence_intervals = np.exp(forecast.conf_int())\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data['Number of Passengers'], label='Observed')\n",
        "plt.plot(forecast_index, forecast_values, label='Forecast', color='red')\n",
        "plt.fill_between(forecast_index, confidence_intervals.iloc[:, 0], confidence_intervals.iloc[:, 1], color='pink', alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The light pink area shows the 95% confidence interval for the forecast.\n",
        "\n",
        "**Question**: What observations do you have about the prediction?\n",
        "\n",
        "\n",
        "# Model Evaluation and Forecasting\n",
        "\n",
        "## Criteria for Model Selection\n",
        "\n",
        "[AIC (Akaike Information Criterion)](https://otexts.com/fpp3/selecting-predictors.html#akaikes-information-criterion):\n",
        "A measure of the relative quality of a statistical model for a given set of data. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{AIC} = T\\log\\left(\\frac{\\text{SSE}}{T}\\right) + 2(k+2)\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $\\text{SSE}$ is the fit of the model as Sum of Squared Error\n",
        "- $T$ is the number of observations,\n",
        "- $k$ is the number of parameters in the model,\n",
        "\n",
        "---\n",
        "\n",
        "[BIC (Bayesian Information Criterion)](https://otexts.com/fpp3/selecting-predictors.html#schwarzs-bayesian-information-criterion):\n",
        "Similar to AIC but includes a penalty term for the number of parameters in the model. It is defined as:\n",
        "\n",
        "$$\n",
        "\\text{BIC} = T\\log\\left(\\frac{\\text{SSE}}{T}\\right) + (k+2)\\log(T)\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $\\text{SSE}$ is the fit of the model as Sum of Squared Error\n",
        "- $T$ is the number of observations,\n",
        "- $k$ is the number of parameters in the model,\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "1. **Model Comparison**: Both AIC and BIC are used to compare different models; the model with the lower AIC or BIC is preferred.\n",
        "2. **Penalty for Complexity**: BIC imposes a larger penalty for models with more parameters compared to AIC.\n",
        "3. **Trade-off**: There is a trade-off between goodness of fit and model complexity.\n",
        "\n",
        "## Cross-Validation Techniques\n",
        "\n",
        "- **Time Series Cross-Validation**: Unlike traditional cross-validation, time series cross-validation respects the temporal order of the data. \n",
        "\n",
        "Common techniques include:\n",
        "\n",
        "- **Rolling Forecast Origin**: The training set is expanded with each iteration, and the model is re-evaluated.\n",
        "- **Time Series Split**: The data is split into multiple training and test sets, ensuring that the training set always precedes the test set.\n",
        "- **Blocked Cross-Validation**: The data is divided into blocks, and each block is used as a test set while the preceding blocks are used for training.\n",
        "\n",
        "**Key Points**:\n",
        "\n",
        "1. **Respect Temporal Order**: Ensure that the training set always precedes the test set to avoid data leakage.\n",
        "2. **Multiple Techniques**: Various techniques like rolling forecast origin, time series split, and blocked cross-validation can be used.\n",
        "\n",
        "## Forecasting and Confidence Intervals\n",
        "\n",
        "- **Forecasting**: The process of making predictions about future values based on historical data. We can use the previously introduced methods such as **ARIMA**, but you can also use **Exponential Smoothing**. This is a technique that applies decreasing weights to past observations, giving more importance to recent data. With exponenetial smoothing you are using a weighted average of past predictions to make a forecast.\n",
        "- **Confidence Intervals**: Provide an estimate of the uncertainty associated with the forecast.\n",
        "  - **Calculation**: Confidence intervals are typically calculated using the standard error of the forecast and a critical value from the t-distribution or normal distribution.\n",
        "  - **Interpretation**: A 95% confidence interval means that there is a 95% chance that the true value will fall within the interval.\n",
        "\n",
        "# Recap and References\n",
        "\n",
        "## Recap\n",
        "\n",
        "We covered the following topics:\n",
        "\n",
        "1. Components of Time Series\n",
        "2. Time Series Decomposition\n",
        "3. Stationarity and Differencing\n",
        "4. Model Selection and Evaluation\n",
        "5. Forecasting and Confidence Intervals\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "- [Wikipedia: Time Series Analysis](https://en.wikipedia.org/wiki/Time_series)\n",
        "- [Time Series Analysis](https://otexts.com/fpp3/)\n",
        "\n",
        "- [Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python/notebook)\n",
        "- [Time Series Data Visualization in Python](https://www.geeksforgeeks.org/time-series-data-visualization-in-python/)\n",
        "\n",
        "## Bibliography\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/ds701/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}