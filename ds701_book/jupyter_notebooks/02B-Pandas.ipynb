{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Essential Tools: Pandas'\n",
        "jupyter: python3\n",
        "code-fold: false\n",
        "---\n",
        "\n",
        "::: {.content-visible when-profile=\"web\"}\n",
        "## Introduction\n",
        "\n",
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tools4ds/DS701-Course-Notes/blob/main/ds701_book/jupyter_notebooks/02B-Pandas.ipynb)\n",
        "\n",
        "In this lecture we discuss one of most useful Python packages for data \n",
        "science -- Pandas.\n",
        "\n",
        "We'll touch on some highlights here, but to learn more, start with the\n",
        "[Pandas Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)\n",
        ":::\n",
        "\n",
        "## Pandas\n",
        "\n",
        "::: {.incremental}\n",
        "\n",
        "- [Pandas](https://pandas.pydata.org/docs/index.html) is a Python library for data\n",
        "manipulation and analysis with an emphasis on tabular data. \n",
        "- It can be used to produce high quality plots and integrates nicely with other\n",
        "  libraries that expect NumPy arrays. \n",
        "- Knowledge and use of Pandas is essential as a data scientist.\n",
        ":::\n",
        "\n",
        ":::: {.fragment}\n",
        "The most important data structure provided by Pandas is the `DataFrame`\n",
        "implemented in the \n",
        "[DataFrame](https://pandas.pydata.org/docs/reference/frame.html) class. \n",
        "::::\n",
        "\n",
        ":::: {.fragment}\n",
        "Unlike a numpy array, a `DataFrame` can have columns of different types.\n",
        "::::\n",
        "\n",
        ":::: {.fragment}\n",
        "Make it a habit that when you're given a tabular dataset, load it into a `DataFrame`.\n",
        "::::\n",
        "\n",
        "## Fetching, storing and retrieving your data\n",
        "\n",
        "For demonstration purposes, we'll use the `yfinance` package to fetch financial \n",
        "data via the Yahoo! API and store it in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# download nvidia stock prices from 2023\n",
        "nvidia_stocks = pd.DataFrame(yf.download('NVDA', start='2023-01-01', end='2023-12-31', progress=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "It's important to inspect the data you are working with and Pandas provides a\n",
        "variety of methods to do so such as `.head()`, `.tail()`, `.info()`,\n",
        "`.describe()`, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "nvidia_stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how each row has a label and each column has a label.\n",
        "\n",
        "---\n",
        "\n",
        "A DataFrame is a python object that has many associated methods to explore and\n",
        "manipulate the data.\n",
        "\n",
        "The method `.info()` gives you a description of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nvidia_stocks.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The method `.describe()` gives you summary statistics of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nvidia_stocks.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading to/from a ``.csv`` file\n",
        "\n",
        "Pandas can read and write dataframes with many file formats such as `.csv`, `.json`, `.parquet`,\n",
        "`.xlsx`, `.html`, `SQL`, etc.\n",
        "\n",
        "Here we write the dataframe to a `.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nvidia_stocks.to_csv('nvidia_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can escape a shell command using the `!` operator to see the top of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!head nvidia_data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "And of course we can likewise read a `.csv` file into a dataframe.  This is probably the most common way you will get data into Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv('nvidia_data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-caution}\n",
        "But be careful, the index column is not automatically set.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the index description.\n",
        "\n",
        "---\n",
        "\n",
        "To set the index column, we can use the `index_col` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv('nvidia_data.csv', index_col=0)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with data columns\n",
        "\n",
        "In general, we'll typically describe the rows in the dataframe as **items** \n",
        "(or **observations** or **data samples**) and the columns as **features**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pandas allows you to reference a column similar to a python dictionary key,\n",
        "using column names in square brackets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['Open']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this returns a `Series` object, the other fundamental data structure in Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "type(df['Open'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also note that Series is indexed in this case by dates rather than simple integers.\n",
        "\n",
        "---\n",
        "\n",
        "Pandas also allows you to refer to columns using an object attribute syntax.\n",
        "\n",
        "Note that the column name cannot include a space in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.Open"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "You can select a list of columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[['Open', 'Close']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Which is just another dataframe, which is why we can chain the `.head()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "type(df[['Open', 'Close']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Changing column names is as simple as assigning to the `.columns` property.\n",
        "\n",
        "Let's adjust the column names to remove spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_column_names = [x.lower().replace(' ', '_') for x in df.columns]\n",
        "df.columns = new_column_names\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe that we first created a list of column names without spaces using __list comprehension__. This is the pythonic way to generate a new list.\n",
        "\n",
        "---\n",
        "\n",
        "Now **all** columns can be accessed using the **dot** notation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.adj_close.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A sampling of DataFrame methods.\n",
        "\n",
        "There are many useful methods in the DataFrame object. It is important to\n",
        "familiarize yourself with these methods.\n",
        "\n",
        "The following methods calculate the mean, standard deviation, and median of the specified numeric columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or we can give a list of columns to the Dataframe object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[['open', 'close', 'volume', 'adj_close']].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or apply the method to a single column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.open.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.high.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting methods\n",
        "\n",
        "Pandas also wraps `matplotlib` and provides a variety of easy-to-use plotting\n",
        "functions directly from the dataframe object.\n",
        "\n",
        "These are your \"first look\" functions and useful in exploratory data analysis.\n",
        "\n",
        "Later, we will use more specialized graphics packages to create more\n",
        "sophisticated visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.high.plot(label='High')\n",
        "df.low.plot(label='Low')\n",
        "plt.title('NVIDIA Stock Price')\n",
        "plt.ylabel('Dollars')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Or a histogram on the adjusted closing price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.adj_close.hist()\n",
        "plt.xlabel('Adjusted Closing Price')\n",
        "plt.ylabel('Dollars')\n",
        "plt.title('NVIDIA Stock Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accessing rows of the DataFrame\n",
        "\n",
        "So far we've seen how to access a column of the DataFrame. To access a row we use different syntax.\n",
        "\n",
        "To access a row by its index label, use the **`.loc()`** method ('location')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.loc['2023-01-23']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a tangent, we can use the `.apply()` method to format the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.loc['2023-01-23'].apply(lambda x: '{:,.2f}'.format(x) if isinstance(x, (int, float)) else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "To access a row by its index number (i.e., like an array index), use **`.iloc()`** ('integer location')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.iloc[0, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and similarly formatted:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.iloc[0, :].apply(lambda x: '{:,.2f}'.format(x) if isinstance(x, (int, float)) else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "To iterate over the rows you can use **`.iterrows()`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_positive_days = 0\n",
        "for idx, row in df.iterrows():\n",
        "    if row.close > row.open:\n",
        "        num_positive_days += 1\n",
        "\n",
        "print(f\"The total number of positive-gain days is {num_positive_days} out of {len(df)} days or as percentage {num_positive_days/len(df):.2%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "This is only capturing the intraday gain/loss, not the cumulative inter-day gain/loss.\n",
        ":::\n",
        "## Filtering\n",
        "\n",
        "It is easy to select rows from the data.  \n",
        "\n",
        "All the operations below return a new Series or DataFrame, which itself can be\n",
        "treated the same way as all Series and DataFrames we have seen so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tmp_high = df.high > 45\n",
        "tmp_high.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summing a Boolean array is the same as counting the number of `True` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sum(tmp_high)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Now, let's select only the rows of `df` that correspond to `tmp_high`. \n",
        "\n",
        "::: {.callout-note}\n",
        "We can pass a series to the dataframe to select rows.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[tmp_high]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Putting it all together, we can count the number of positive days without iterating over the rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positive_days = df[df.close > df.open]\n",
        "print(f\"Total number of positive-gain days is {len(positive_days)}\")\n",
        "positive_days.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Or count the number of days with a gain of more than $2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "very_positive_days = df[(df.close - df.open) > 2]\n",
        "print(f\"Total number of days with gain > $2 is {len(very_positive_days)}\")\n",
        "very_positive_days.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this doesn't the explain the total gain for the year. Why?\n",
        "\n",
        "## Creating new columns\n",
        "\n",
        "To create a new column, simply assign values to it. The column name is similar to a key in a dictionary.\n",
        "\n",
        "Let's look at the daily change in closing price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the daily change in closing price\n",
        "df['daily_change'] = df['close'].diff()\n",
        "\n",
        "# Create the cumulative profit column\n",
        "df['cum_profit'] = df['daily_change'].cumsum()\n",
        "\n",
        "# Display the first few rows to verify the new column\n",
        "print(df[['close', 'daily_change', 'cum_profit']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is convenient that `.diff()` by default is the difference between the current and previous row.\n",
        "\n",
        "---\n",
        "\n",
        "Let's look at the histogram of the daily change in stock price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot histogram of daily_change\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['daily_change'].hist(bins=50, edgecolor='black')\n",
        "plt.title('Histogram of Daily Change in Stock Price')\n",
        "plt.xlabel('Daily Change')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Let's give each row a `gain` value as a categorical variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for idx, row in df.iterrows():\n",
        "    if row.daily_change < 0:\n",
        "        df.loc[idx,'cat_gain']='negative'\n",
        "    elif row.daily_change < 1:\n",
        "        df.loc[idx,'cat_gain']='small_gain'\n",
        "    elif row.daily_change < 2:\n",
        "        df.loc[idx,'cat_gain']='medium_gain'\n",
        "    elif row.daily_change >= 2:\n",
        "        df.loc[idx,'cat_gain']='large_gain'\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Here is another, more \"functional\", way to accomplish the same thing.\n",
        "\n",
        "First, let's drop the gain column so we can start fresh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.drop('cat_gain', axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Define a function that classifies rows, and `apply` it to each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def namerow(row):\n",
        "    if row.daily_change < 0:\n",
        "        return 'negative'\n",
        "    elif row.daily_change < 1:\n",
        "        return 'small_gain'\n",
        "    elif row.daily_change < 2:\n",
        "        return 'medium_gain'\n",
        "    elif row.daily_change >= 2:\n",
        "        return 'large_gain'\n",
        "\n",
        "df['cat_gain'] = df.apply(namerow, axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouping\n",
        "\n",
        "A powerful DataFrame method is `groupby()`. \n",
        "\n",
        "This is analagous to `GROUP BY` in SQL.\n",
        "\n",
        "It will group the rows of a DataFrame by the values in one (or more) columns and let you iterate through each group.\n",
        "\n",
        "Here we will look at the average gain among the categories of gains (negative, small, medium, and large) we defined above and stored in the column `gain`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gain_groups = df.groupby(by='cat_gain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Essentially, `gain_groups` behaves like a dictionary:\n",
        "\n",
        "* the keys are the unique values found in the `gain` column, and \n",
        "* the values are DataFrames that contain only the rows having the corresponding unique values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for gain, gain_data in gain_groups:\n",
        "    print(gain)\n",
        "    print(gain_data[['close', 'daily_change']].head())\n",
        "    print('=============================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for gain, gain_data in df.groupby(\"cat_gain\"):\n",
        "    print('The average daily change for the {} group is {}'.format(gain,\n",
        "                                                           gain_data.daily_change.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other Pandas Classes\n",
        "\n",
        "A DataFrame is essentially an annotated 2-D array.\n",
        "\n",
        "Pandas also has annotated versions of 1-D and 3-D arrays.\n",
        "\n",
        "A 1-D array in Pandas is called a [Series](https://pandas.pydata.org/docs/reference/series.html). \n",
        "You can think of DataFrames as a dictionary of Series.\n",
        "\n",
        "A 3-D array in Pandas is created using a\n",
        "[MultiIndex](https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html#).\n",
        "\n",
        "For more information read the documentation.\n",
        "\n",
        "## Comparing multiple stocks\n",
        "\n",
        "As a last task, we will use the experience we obtained so far -- and learn some\n",
        "new things -- in order to compare the performance of different stocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stocks = ['NVDA', 'META', 'MSFT', 'TSLA', 'IBM', 'INTC']\n",
        "stock_df = pd.DataFrame()\n",
        "for s in stocks:\n",
        "    stock_df[s] = pd.DataFrame(yf.download(s, \n",
        "                                           start='2023-09-01', \n",
        "                                           end='2024-08-30', \n",
        "                                           progress=False))['Close']\n",
        "stock_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Let's look at the closing prices of the stocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "stock_df.plot()\n",
        "plt.title('Stock Closing Prices')\n",
        "plt.ylabel('Dollars')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But that is not as interesting as the returns.\n",
        "\n",
        "---\n",
        "\n",
        "So next, we calculate the returns over a period of length $T$. The returns are defined as\n",
        "\n",
        "$$\n",
        "r(t) = \\frac{f(t)-f(t-T)}{f(t-T)}. \n",
        "$$\n",
        "\n",
        "The returns can be computed with a simple DataFrame method `pct_change()`.  Note that for the first $T$ timesteps, this value is not defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rets = stock_df.pct_change(30)\n",
        "rets.iloc[25:35]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Now we'll plot the timeseries of the rolling 30-day returns of the different stocks.\n",
        "\n",
        "Notice that the `NaN` values are dropped by the plotting function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rets[['NVDA', 'META']].plot()\n",
        "plt.ylabel('Returns (%)')\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.2f}%'.format(y * 100)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Let's do a scatter plot of the returns of NVDA versus META."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(rets.NVDA, rets.META)\n",
        "plt.xlabel('NVDA 30-day returns')\n",
        "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.2f}%'.format(y * 100)))\n",
        "plt.ylabel('META 30-day returns')\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.2f}%'.format(y * 100)))\n",
        "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There appears to be some (fairly strong) correlation between the movement of\n",
        "NVDA and META stocks.  Let's measure this.\n",
        "\n",
        "---\n",
        "\n",
        "The correlation coefficient between variables $X$ and $Y$ is defined as follows\n",
        "\n",
        "$$\n",
        "\\text{Corr}(X,Y) = \\frac{E\\left[(X-\\mu_X)(Y-\\mu_Y)\\right]}{\\sigma_X\\sigma_Y}. \n",
        "$$\n",
        "\n",
        "Pandas provides a DataFrame method called `corr()` that computes the correlation coefficient of all pairs of columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rets.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It takes a bit of time to examine that table and draw conclusions.  \n",
        "\n",
        "---\n",
        "\n",
        "To speed that process up let's visualize the table.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(rets.corr(), annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does seem like there is a strong correlation between NVDA and META.\n",
        "\n",
        "What about TSLA and META?\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(rets.TSLA, rets.META)\n",
        "plt.xlabel('TESLA 30-day returns')\n",
        "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.2f}%'.format(y * 100)))\n",
        "plt.ylabel('META 30-day returns')\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.2f}%'.format(y * 100)))\n",
        "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What can we say about the 30-day returns of TSLA and META?\n",
        "\n",
        "---\n",
        "\n",
        "## Pandas plotting\n",
        "\n",
        "As mentioned, the plotting performed by Pandas is just a layer on top of\n",
        "`matplotlib` (i.e., the `plt` package).  \n",
        "\n",
        "So Panda's plots can (and often should) be replaced or improved by using\n",
        "additional functions from `matplotlib`.\n",
        "\n",
        "For example, suppose we want to know both the returns as well as the standard\n",
        "deviation of the returns of a stock (i.e., its risk).  \n",
        "\n",
        "---\n",
        "\n",
        "Here is a visualization of the result of such an analysis. We construct the plot using only functions from `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(rets.mean(), rets.std())\n",
        "plt.xlabel('Expected returns')\n",
        "plt.ylabel('Standard Deviation (Risk)')\n",
        "plt.xlim([-.05, .1])\n",
        "plt.ylim([0, .3])\n",
        "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
        "    plt.annotate(\n",
        "        label, \n",
        "        xy = (x, y), xytext = (30, -30),\n",
        "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
        "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
        "        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To understand what these functions are doing, (especially the\n",
        "[annotate](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html)\n",
        "function), you will need to consult the online documentation for\n",
        "[matplotlib](https://matplotlib.org/stable/api/index.html). \n",
        "\n",
        "## Recap\n",
        "\n",
        "In this section we got a first glimpse of the Pandas library.\n",
        "\n",
        "We learned how to:\n",
        "\n",
        "* load data from a CSV file\n",
        "* inspect the data\n",
        "* manipulate the data\n",
        "* plot the data\n",
        "* access rows and columns of the dataframe\n",
        "* filter the data\n",
        "* create new columns\n",
        "* group the data\n",
        "* compute the correlation between variables"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/ds701/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}